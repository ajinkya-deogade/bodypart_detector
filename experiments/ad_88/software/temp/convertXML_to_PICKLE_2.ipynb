{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import pandas as pd\n",
    "import time\n",
    "import cPickle\n",
    "import os\n",
    "from joblib import Parallel, delayed\n",
    "import multiprocessing\n",
    "\n",
    "num_cores = multiprocessing.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFrameData(root, iterKey):\n",
    "    allFrameData = []\n",
    "    for frameData in root.iter(iterKey):\n",
    "        if not frameData.attrib:\n",
    "            allFrameData.append(frameData.text)\n",
    "        else:\n",
    "            allFrameData.append(frameData.attrib)\n",
    "    return allFrameData\n",
    "\n",
    "def readRuleData(file_name):\n",
    "    tree = ET.parse(file_name)\n",
    "    root = tree.getroot()\n",
    "    parent = {}\n",
    "    for child in root:\n",
    "        tempList = list(child)\n",
    "    #     print child.tag\n",
    "        if not tempList:\n",
    "            if not child.attrib:\n",
    "                parent[child.tag] = child.text\n",
    "            else:\n",
    "                parent[child.tag] = child.attrib\n",
    "        else:\n",
    "            parent[child.tag] = {}\n",
    "            for grand_child in child:\n",
    "    #             print '\\t', grand_child.tag\n",
    "                tempList = list(grand_child)\n",
    "                if not tempList:\n",
    "                    if not grand_child.attrib:\n",
    "                        parent[child.tag][grand_child.tag] = grand_child.text\n",
    "                    else:\n",
    "                        parent[child.tag][grand_child.tag] = grand_child.attrib\n",
    "                else:\n",
    "                    parent[child.tag][grand_child.tag] = {}\n",
    "                    for grand_grand_child in grand_child:\n",
    "    #                     print '\\t\\t', grand_grand_child.tag\n",
    "                        tempList = list(grand_grand_child)\n",
    "                        if not tempList:\n",
    "                            if not grand_grand_child.attrib:\n",
    "                                parent[child.tag][grand_child.tag][grand_grand_child.tag] = grand_grand_child.text\n",
    "                            else:\n",
    "                                parent[child.tag][grand_child.tag][grand_grand_child.tag] = grand_grand_child.attrib\n",
    "                        else:\n",
    "                            parent[child.tag][grand_child.tag][grand_grand_child.tag] = {}\n",
    "                            for grand_grand_grand_child in grand_grand_child:\n",
    "    #                             print '\\t\\t\\t', grand_grand_grand_child.tag\n",
    "                                tempList = list(grand_grand_grand_child)\n",
    "                                if not tempList:\n",
    "                                    if not grand_grand_grand_child.attrib:\n",
    "                                        parent[child.tag][grand_child.tag][grand_grand_child.tag][grand_grand_grand_child.tag] = grand_grand_grand_child.text\n",
    "                                    else:\n",
    "                                        parent[child.tag][grand_child.tag][grand_grand_child.tag][grand_grand_grand_child.tag] = grand_grand_grand_child.attrib\n",
    "                                else:\n",
    "                                    parent[child.tag][grand_child.tag][grand_grand_child.tag][grand_grand_grand_child.tag] = {}\n",
    "                                    for grand_grand_grand_grand_child in grand_grand_grand_child:\n",
    "            #                             print '\\t\\t\\t', grand_grand_grand_grand_child.tag\n",
    "                                        tempList = list(grand_grand_grand_grand_child)\n",
    "                                        if not tempList:\n",
    "                                            if not grand_grand_grand_grand_child.attrib:\n",
    "                                                parent[child.tag][grand_child.tag][grand_grand_child.tag][grand_grand_grand_child.tag][grand_grand_grand_child.tag] = grand_grand_grand_child.text\n",
    "                                            else:\n",
    "                                                parent[child.tag][grand_child.tag][grand_grand_child.tag][grand_grand_grand_child.tag][grand_grand_grand_child.tag] = grand_grand_grand_child.attrib\n",
    "                                        else:\n",
    "                                            print \"There are more grand childrens than you think\"\n",
    "    parent['ruleData'] = []\n",
    "    parent['ruleData'] = pd.DataFrame(getFrameData(root, 'ruleData'))\n",
    "    \n",
    "    return parent\n",
    "\n",
    "def readKinData(file_name, inum):\n",
    "    print 'Parsing File Number ', inum\n",
    "    tree = ET.parse(file_name)\n",
    "    root = tree.getroot()\n",
    "    \n",
    "    kinData = []\n",
    "    kinetics = []\n",
    "    stimulus = []\n",
    "\n",
    "    larvaFrameData = pd.DataFrame(getFrameData(root, 'larvaFrameData'))\n",
    "    skeleton = pd.DataFrame(getFrameData(root, 'skeleton'))\n",
    "    kinetics = pd.concat([larvaFrameData.reset_index(drop=True), skeleton.reset_index(drop=True)], axis=1)\n",
    "\n",
    "    midpoint = pd.DataFrame(getFrameData(root, 'midpoint'), dtype=np.float16)\n",
    "    midpoint.rename(columns={'x': 'mid_x', 'y': 'mid_y'}, inplace=True)\n",
    "    midpoint.reset_index(inplace=True, drop=True)\n",
    "    centroid = pd.DataFrame(getFrameData(root, 'centroid'), dtype=np.float16)\n",
    "    centroid.rename(columns={'x': 'cent_x', 'y': 'cent_y'}, inplace=True)\n",
    "    centroid.reset_index(inplace=True, drop=True)\n",
    "    head = pd.DataFrame(getFrameData(root, 'head'), dtype=np.float16)\n",
    "    head.rename(columns={'x': 'head_x', 'y': 'head_y'}, inplace=True)\n",
    "    head.reset_index(inplace=True, drop=True)\n",
    "    tail = pd.DataFrame(getFrameData(root, 'tail'), dtype=np.float16)\n",
    "    tail.rename(columns={'x': 'tail_x', 'y': 'tail_y'}, inplace=True)\n",
    "    tail.reset_index(inplace=True, drop=True)    \n",
    "    featureLocation = pd.DataFrame(getFrameData(root, 'featureLocation'), dtype=np.float16)\n",
    "    s = featureLocation.copy()\n",
    "    all_feature_df = pd.DataFrame([])\n",
    "    all_feat = s.name.unique()\n",
    "    for feat in all_feat:\n",
    "        d = s.loc[s['name'] == feat, ['numberMaximumVotes', 'numberVotes', 'x', 'y']]\n",
    "        d.rename(columns={'numberMaximumVotes': feat + '_maxVotes', \n",
    "                          'numberVotes': feat + '_votes',\n",
    "                          'x': feat + '_x',\n",
    "                          'y': feat + '_y'}, inplace=True)\n",
    "        all_feature_df = pd.concat([all_feature_df, d.reset_index(drop=True)], axis=1)\n",
    "    \n",
    "    stimulusIntensity = pd.DataFrame(getFrameData(root, 'intensityPercentage'))\n",
    "    temp = pd.DataFrame(getFrameData(root, 'ledArrayStimulus'))\n",
    "    \n",
    "    if not temp.empty:\n",
    "        stimulus = pd.concat([temp.reset_index(drop=True), stimulusIntensity.reset_index(drop=True)], axis=1)\n",
    "        stimulus.rename(columns={0: 'intensity'}, inplace=True)\n",
    "    else:\n",
    "        stimulus = stimulusIntensity\n",
    "    \n",
    "    kinData = pd.concat([kinetics.reset_index(drop=True), midpoint, centroid, head, tail, all_feature_df, stimulus.reset_index(drop=True)], axis=1)\n",
    "    kinData['num'] = inum\n",
    "    kinData['timeIndex'] = kinData.index.values\n",
    "\n",
    "    return kinData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "venkman-log-20180316-062750100-sid-1.xml\n",
      "venkman-log-20180316-063825616-sid-2.xml\n",
      "Total XML Files Found -  2\n"
     ]
    }
   ],
   "source": [
    "# data_dir = '20180316_OK6_CsChrimson_Tail_200micron'\n",
    "data_dir = '20180316_OK6_CsChrimson_Tail_200micron'\n",
    "\n",
    "all_xml_files = []\n",
    "root_path = '/Volumes/GoogleDrive/My Drive/CRG_Dropbox/AljoComputer/Matlab/high_res_tracker/Data/'\n",
    "data_dir = os.path.join(root_path,data_dir,'XML')\n",
    "for file in os.listdir(data_dir):\n",
    "    if file.endswith(\".xml\"):\n",
    "        print file\n",
    "        all_xml_files.append(os.path.join(data_dir, file))\n",
    "\n",
    "print \"Total XML Files Found - \", len(all_xml_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing File Number  0\n",
      "Parsing File Number  1\n",
      "Time taken to parse 2 files in parallel is 35.543 sec\n"
     ]
    }
   ],
   "source": [
    "## Parse Files in Parallel\n",
    "tStart = time.time()\n",
    "kin_data = []\n",
    "kin_data = Parallel(n_jobs=num_cores)(delayed(readKinData)(xml_file, idx) for idx, xml_file in enumerate(all_xml_files))\n",
    "print 'Time taken to parse %d files in parallel is %0.3f sec'%(len(all_xml_files), time.time()-tStart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to parse rule data is 22.760 sec\n"
     ]
    }
   ],
   "source": [
    "## Parse Files in Parallel\n",
    "tStart = time.time()\n",
    "rule_data = []\n",
    "rule_data = readRuleData(all_xml_files[0])\n",
    "print 'Time taken to parse rule data is %0.3f sec' %(time.time()-tStart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "kin_data_all=[]\n",
    "kin_data_all = pd.concat(kin_data)\n",
    "kin_data_all.reset_index(inplace=True)\n",
    "\n",
    "## Save Parsed Files\n",
    "kin_data_all.to_csv(open(os.path.join(data_dir, 'kinData_xml.dat'), 'wb'), sep='\\t', index=False)\n",
    "cPickle.dump(rule_data, open(os.path.join(data_dir, 'ruleData_xml.pkl'), 'wb'), protocol=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Parse Files Sequentially\n",
    "# c=0\n",
    "# for xml_file in all_xml_files:\n",
    "#     tStart = time.time()\n",
    "#     temp = readXMLFile(xml_file)\n",
    "#     kin_data.append(readXMLFile(xml_file))\n",
    "#     c+=1\n",
    "#     print 'Time taken to parse file %d is %0.3f'%(c, time.time()-tStart)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
