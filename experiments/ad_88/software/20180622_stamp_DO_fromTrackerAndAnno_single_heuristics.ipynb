{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-23T17:17:17.102768Z",
     "start_time": "2018-07-23T17:17:16.485370Z"
    },
    "code_folding": [
     20,
     25,
     29,
     49
    ],
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import struct\n",
    "\n",
    "# Headers for different tables\n",
    "meta_data_header = ['FrameNumber', 'Time', 'Stage_x', 'Stage_y', 'Centroid_x', 'Centroid_y',\n",
    "                    'Midpoint_x', 'Midpoint_y', 'Head_x', 'Head_y', 'Tail_x', 'Tail_y', 'MouthHook_x', 'MouthHook_y',\n",
    "                    'LeftMHhook_x', 'LeftMHhook_y', 'RightMHhook_x', 'RightMHhook_y',\n",
    "                    'LeftDorsalOrgan_x', 'LeftDorsalOrgan_y', 'RightDorsalOrgan_x', 'RightDorsalOrgan_y',\n",
    "                    'CenterBolwigOrgan_x', 'CenterBolwigOrgan_y', 'LeftBolwigOrgan_x', 'LeftBolwigOrgan_y',\n",
    "                    'RightBolwigOrgan_x', 'RightBolwigOrgan_y', 'V9_x', 'V9_y', 'V10_x', 'V10_y', 'V11_x', 'V11_y',\n",
    "                    'V12_x', 'V12_y', 'V13_x', 'V13_y', 'V14_x', 'V14_y', 'V15_x', 'V15_y', 'V16_x', 'V16_y',\n",
    "                    'MouthHook_votes', 'LeftMHhook_votes', 'RightMHhook_votes', 'LeftDorsalOrgan_votes',\n",
    "                    'RightDorsalOrgan_votes', 'CenterBolwigOrgan_votes', 'LeftBolwigOrgan_votes', 'RightBolwigOrgan_votes',\n",
    "                    'V9_votes', 'V10_votes', 'V11_votes', 'V12_votes', 'V13_votes', 'V14_votes', 'V15_votes',\n",
    "                    'V16_votes', 'Num_Key_points']\n",
    "\n",
    "coordinate_header = ['FrameNumber', 'MouthHook_x', 'MouthHook_y', 'LeftMHhook_x', 'LeftMHhook_y',\n",
    "                     'RightMHhook_x', 'RightMHhook_y', 'LeftDorsalOrgan_x', 'LeftDorsalOrgan_y',\n",
    "                     'RightDorsalOrgan_x', 'RightDorsalOrgan_y', 'CenterBolwigOrgan_x', 'CenterBolwigOrgan_y',\n",
    "                     'LeftBolwigOrgan_x', 'LeftBolwigOrgan_y', 'RightBolwigOrgan_x', 'RightBolwigOrgan_y']\n",
    "\n",
    "distance_header = ['MouthHook', 'LeftMHhook',\n",
    "                   'RightMHhook', 'LeftDorsalOrgan', 'RightDorsalOrgan',\n",
    "                   'CenterBolwigOrgan', 'LeftBolwigOrgan', 'RightBolwigOrgan']\n",
    "\n",
    "def readSplineData(fileName, nFrames):\n",
    "    fCount = 0;\n",
    "    spline = {}\n",
    "    with open(fileName, \"rb\") as f:\n",
    "        while (True) and (fCount < nFrames-1):\n",
    "            fCount += 1\n",
    "            gap, frameNumber = struct.unpack('>ii', f.read(struct.calcsize('>ii')))\n",
    "\n",
    "            nPointsToRead =  struct.unpack('>i', f.read(struct.calcsize('>i')))\n",
    "            fmt = \">%dH\" % (nPointsToRead)\n",
    "            tempX = struct.unpack(fmt, f.read(struct.calcsize(fmt)))\n",
    "\n",
    "            nPointsToRead =  struct.unpack('>i', f.read(struct.calcsize('>i')))\n",
    "            fmt = \">%dH\" % (nPointsToRead)\n",
    "            tempY = struct.unpack(fmt, f.read(struct.calcsize(fmt)))\n",
    "            \n",
    "            spline[frameNumber-1] = np.vstack((np.asarray(tempX).T, np.asarray(tempY).T))\n",
    "\n",
    "    return spline\n",
    "\n",
    "def readContourData(fileName, nFrames):    \n",
    "    fCount = 0;\n",
    "    contour = {}\n",
    "    with open(fileName, \"rb\") as f:\n",
    "        while (True) and (fCount < nFrames-1):\n",
    "            fCount += 1\n",
    "            frameNumber = struct.unpack('>i', f.read(struct.calcsize('>i')))\n",
    "\n",
    "            nPointsToRead = struct.unpack('>i', f.read(struct.calcsize('>i')))            \n",
    "            fmt = \">%dH\" %(nPointsToRead)\n",
    "            buff = f.read(struct.calcsize(fmt))\n",
    "            tempX = struct.unpack(fmt, buff)\n",
    "            \n",
    "            nPointsToRead = struct.unpack('>i', f.read(struct.calcsize('>i')))\n",
    "            fmt = \">%dH\" %(nPointsToRead)\n",
    "            buff = f.read(struct.calcsize(fmt))\n",
    "            tempY = struct.unpack(fmt, buff)\n",
    "            \n",
    "            frameNumber = frameNumber[0]\n",
    "            contour[frameNumber-1] = np.vstack((np.asarray(tempX).T, np.asarray(tempY).T))\n",
    "\n",
    "    return contour\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-23T17:17:33.057636Z",
     "start_time": "2018-07-23T17:17:17.110107Z"
    },
    "code_folding": [
     19,
     26
    ],
    "hide_input": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## 20170317_7c0\n",
    "# root = '../expts/trainingData_20170317_7c0/'\n",
    "\n",
    "## 20180417_7c1_Hess_100\n",
    "# root = '../expts/trainingData_20180417_7c1/'\n",
    "\n",
    "## 20180417_7c1_Hess_50\n",
    "# root = '../expts/20180417_7c1_Hess_50/'\n",
    "\n",
    "## 20180417_7c1_Hess_25\n",
    "# root = '../expts/20180417_7c1_Hess_25/'\n",
    "\n",
    "## 20180417_7c1_Hess_100_Nbr_25\n",
    "# root = '../expts/trainingData_20180417_7c1_Nbr_25/'\n",
    "\n",
    "## 20180417_7c1_Hess_100_Nbr_25\n",
    "# root = '../expts/trainingData_20180417_7c1_Nbr_25_ROI_128/'\n",
    "\n",
    "## 20180417_7c1_Hess_100_ROI_128\n",
    "# root = '../expts/trainingData_20180417_7c1_Hess_100_ROI_128/'\n",
    "\n",
    "# 20180417_Individual\n",
    "# root = '../expts/trainingData_20180417_Individual/'\n",
    "\n",
    "# 20180417_7c1_Hess_100_BothDO\n",
    "root = '../expts/trainingData_20180417_7c1_Hess_100_BothDO/'\n",
    "\n",
    "# test_dir = root + 'dataCollectedOn_20180417_grp_1/Rawdata_20180417_084502_20180423_075225/'\n",
    "# test_string = \"Rawdata_20180417_084502\" ## Start frame in zero index\n",
    "\n",
    "# test_dir = root + 'dataCollectedOn_20180417_grp_2/Rawdata_20180417_083618_20180420_104633/'\n",
    "# test_string = \"Rawdata_20180417_083618\" ## Start frame in zero index\n",
    "\n",
    "test_dir = root + 'dataCollectedOn_20180417_grp_3/Rawdata_20180417_082627_20180525_112343_A_133410/'\n",
    "test_string = \"Rawdata_20180417_082627\" ## Start frame in zero index\n",
    "\n",
    "# test_dir = root + 'dataCollectedOn_20180417_grp_4/Rawdata_20180417_075246_20180420_092232_A_095851/'\n",
    "# test_string = \"Rawdata_20180417_075246\" ## Start frame in zero index\n",
    "\n",
    "# test_dir = root + 'dataCollectedOn_20180417_grp_5/Rawdata_20180417_072307_20180523_100127_A_122116/'\n",
    "# test_string = \"Rawdata_20180417_072307\" ## Start frame in zero index\n",
    "\n",
    "# test_dir = root + 'dataCollectedOn_20180417_grp_6/Rawdata_20180417_070739_20180522_151012/'\n",
    "# test_string = \"Rawdata_20180417_070739\" ## Start frame in zero index\n",
    "\n",
    "# test_dir = root + 'dataCollectedOn_20180417_grp_7/Rawdata_20180417_065725_20180522_114055/'\n",
    "# test_string = \"Rawdata_20180417_065725\" ## Start frame in zero index\n",
    "\n",
    "# ## 20170317_7c1\n",
    "# root = '../expts/trainingData_20170317_7c1/'\n",
    "\n",
    "# ## 20180417_7c0\n",
    "# root = '../expts/trainingData_20180417_7c0/'\n",
    "\n",
    "# 20170318_5c0_test_170317\n",
    "# root = '../expts/trainingData_20170318_5c0_test_170317/'\n",
    "\n",
    "# test_dir = root + 'dataCollectedOn_20170317_grp_1/Rawdata_20170317_233847_20170321_034501/'\n",
    "# test_string = \"Rawdata_20170317_233847\" ## Start frame in zero index\n",
    "\n",
    "## Set path to the directory with video file\n",
    "video_path = '../expts/videos_20180417/'\n",
    "# video_path = '../expts/videos_20170317/'\n",
    "\n",
    "video_file = os.path.join(video_path, test_string+\".avi\")\n",
    "# video_file = os.path.join(video_path, test_string+\".mp4\")\n",
    "test_string_2 = str.split(test_string, '_')[2]\n",
    "\n",
    "crop_size = 512\n",
    "spot_size = 18.22\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "\n",
    "## Read tracker metadata and annotation\n",
    "for fs in os.listdir(test_dir):\n",
    "    if 'Metadata' in fs:\n",
    "        meta_data = pd.read_csv(os.path.join(test_dir, fs), sep=',', header=0, names=meta_data_header)\n",
    "    if 'Coordinates' in fs:\n",
    "        coordinates = pd.read_csv(os.path.join(test_dir, fs), sep=',', names=coordinate_header)\n",
    "\n",
    "numPoints = len(meta_data.index.values) + 1\n",
    "for fs in os.listdir(test_dir):\n",
    "    if 'Contour' in fs:\n",
    "        contour = readContourData(os.path.join(test_dir, fs), numPoints)\n",
    "    if 'SPLINE' in fs:        \n",
    "        spline = readSplineData(os.path.join(test_dir, fs), numPoints)\n",
    "        \n",
    "if (meta_data.empty is False):\n",
    "\n",
    "    ## OpenCV object for reading video files\n",
    "    cap = cv2.VideoCapture(video_file)\n",
    "\n",
    "    ## Total number of videos in the video file\n",
    "    numberFrames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "    ## Make the metadata frame umber start from 0 index\n",
    "    meta_data.loc[:, 'FrameNumber'] = meta_data.loc[:, 'FrameNumber'] - 1\n",
    "    meta_data.set_index('FrameNumber', inplace=True)\n",
    "\n",
    "    ## Make the annotation frame umber start from 0 index\n",
    "    coordinates = coordinates.round(0)\n",
    "    start_frame = coordinates.loc[0, 'FrameNumber'].copy() - 1\n",
    "    coordinates.loc[:, 'FrameNumber'] = coordinates.loc[:, 'FrameNumber'] - start_frame\n",
    "    coordinates.set_index('FrameNumber', inplace=True)\n",
    "    \n",
    "    ## Get index of no annotations\n",
    "    no_anno = np.array(np.where(coordinates.values == -1)).T\n",
    "    temp_index = coordinates.iloc[no_anno[:, 0], :].index.values\n",
    "    temp_cols = coordinates.iloc[:,no_anno[:, 1]].columns.values\n",
    "    no_anno_cols = []\n",
    "    no_anno_index = []        \n",
    "    for i in range(0, len(temp_cols), 2):\n",
    "        no_anno_cols.append(temp_cols[i][:-2])\n",
    "        no_anno_index.append(temp_index[i])\n",
    "    no_anno_df = pd.DataFrame({'index': no_anno_index, 'col': no_anno_cols})\n",
    "\n",
    "    ## Inner join to take only the frames intersecting the annotation and tracker metadata\n",
    "    ## Use when want to see only annotated frames \n",
    "    meta_coord = pd.merge(meta_data, coordinates, on='FrameNumber', how='inner', suffixes=('_T', '_A'))\n",
    "\n",
    "    ## Outer join to take only the frames intersecting the annotation and tracker metadata\n",
    "    ## Use when want to see all frames \n",
    "#     meta_coord = pd.merge(meta_data, coordinates, on='FrameNumber', how='outer', suffixes=('_T', '_A'))\n",
    "\n",
    "    ## Calculate distance between annotation and the tracker metadata\n",
    "    for head in distance_header:\n",
    "        temp_x = (meta_coord[head+'_x_T'].values - meta_coord[head+'_x_A'].values)**2\n",
    "        temp_y = (meta_coord[head+'_y_T'].values - meta_coord[head+'_y_A'].values)**2\n",
    "        meta_coord.loc[:, head+'_dist'] = np.sqrt(temp_x + temp_y)\n",
    "\n",
    "    ## Replace the no annotation with NA\n",
    "    for rind, rval in no_anno_df.iterrows():\n",
    "        meta_coord.loc[rval['index'], rval['col']+'_dist'] = np.nan\n",
    "\n",
    "    ## Replace NaN values with a high negative number\n",
    "    meta_coord.dropna(axis=0, how='any', inplace=True)\n",
    "\n",
    "    ## Initialization of VideoWriterObject to save the whole frame\n",
    "    ## Uncomment below when want to save the whole frame\n",
    "#     outputFrameSize = np.multiply(np.ones((1880, 1880, 3), dtype=np.uint8), 255)\n",
    "#     outputFrameSize = np.multiply(np.ones((1920, 1920, 3), dtype=np.uint8), 255)\n",
    "#     height, width, layers = outputFrameSize.shape\n",
    "#     outputVideoFile = os.path.join(test_dir, '_'.join(str.split(test_string, '_')[0:3]) + '.avi')\n",
    "#     video = cv2.VideoWriter(outputVideoFile, 0, 5, (width, height))\n",
    "\n",
    "    ## Initialization of VideoWriterObject to save the cropped frame\n",
    "    outputFrameSize_crop = np.multiply(np.ones((crop_size, crop_size, 3), dtype=np.uint8), 255)\n",
    "    height_crop, width_crop, layers_crop = outputFrameSize_crop.shape\n",
    "    outputVideoFile_crop = os.path.join(test_dir, '_'.join(str.split(test_string, '_')[0:3]) + '_crop.avi')\n",
    "    video_crop = cv2.VideoWriter(outputVideoFile_crop, 0, 5, (width_crop, height_crop))\n",
    "\n",
    "    ## Check if the video is readable\n",
    "    if cap.isOpened():\n",
    "        for row_index, row in meta_coord.iterrows():\n",
    "            this_frame = row_index + start_frame\n",
    "\n",
    "            ## Set the frame number to be read from the Video\n",
    "            cap.set(1, this_frame)\n",
    "\n",
    "            ## Read the set frame from the Video\n",
    "            ret, originalFrame = cap.read()\n",
    "#             print this_frame,\n",
    "#             print ret,\n",
    "\n",
    "            ## Make copies of the frame for later use\n",
    "            frame = originalFrame.copy()\n",
    "            frame_overlay = originalFrame.copy()\n",
    "            \n",
    "            cv2.drawContours(frame, [contour[row_index].T.astype(np.int32)], 0, (175,175,175), 3)\n",
    "            cv2.polylines(frame, [spline[row_index].T.astype(np.int32)], False, (125,125,225))\n",
    "\n",
    "            ## Use head position as the crop center\n",
    "            cropCenter_X = int(row['Head_x'])\n",
    "            cropCenter_Y = int(row['Head_y'])\n",
    "\n",
    "            ## Mark the head position with a '+' sign\n",
    "            cv2.putText(frame_overlay, '+', (int(cropCenter_X), int(cropCenter_Y)), font, 0.65, (0, 0, 0), 3, cv2.LINE_AA)\n",
    "\n",
    "#################################################################################################################\n",
    "########################################## Work out heuristics ##############################################\n",
    "#################################################################################################################\n",
    "            nkp = float(row['Num_Key_points'] + 1)\n",
    "            mh = [int(row['MouthHook_x_T']), int(row['MouthHook_y_T']), float(row['MouthHook_votes'])/nkp, int(spot_size)/2]\n",
    "            ldo = [int(row['LeftDorsalOrgan_x_T']), int(row['LeftDorsalOrgan_y_T']), float(row['LeftDorsalOrgan_votes'])/nkp, int(spot_size)/2]\n",
    "            rdo = [int(row['RightDorsalOrgan_x_T']), int(row['RightDorsalOrgan_y_T']), float(row['RightDorsalOrgan_votes'])/nkp, int(spot_size)/2]\n",
    "            lmh = [int(row['LeftMHhook_x_T']), int(row['LeftMHhook_y_T']), float(row['LeftMHhook_votes'])/nkp, int(spot_size)/4]\n",
    "            rmh = [int(row['RightMHhook_x_T']), int(row['RightMHhook_y_T']), float(row['RightMHhook_votes'])/nkp, int(spot_size)/4]\n",
    "            \n",
    "#             if (ldo[2] < 0.1) and (lmh[2] >= 0.1):\n",
    "#                 ldo[0], ldo[1], ldo[3] = lmh[0], lmh[1], lmh[3]*4\n",
    "#             if (rdo[2] < 0.1) and (rmh[2] >= 0.1):\n",
    "#                 rdo[0], rdo[1], rdo[3] = rmh[0], rmh[1], rmh[3]*4                \n",
    "            \n",
    "#################################################################################################################\n",
    "############################### Mark the detected positions by the tracker using a rectangle ####################\n",
    "#################################################################################################################\n",
    "            min_conf_mh = 0.0\n",
    "            min_conf_ldo = 0.0\n",
    "            min_conf_rdo = 0.0\n",
    "            min_conf_lmh = 0.0\n",
    "            min_conf_rmh = 0.0\n",
    "            min_kp = 5\n",
    "    \n",
    "            ## Tracker - MouthHook\n",
    "            if nkp >= min_kp:\n",
    "                if mh[2] > min_conf_mh:\n",
    "                    cv2.rectangle(frame_overlay, (mh[0] - mh[3], mh[1] - mh[3]),\n",
    "                                  (mh[0] + mh[3], mh[1] + mh[3]),\n",
    "                                  color=(255, 0, 0), thickness=-1)\n",
    "\n",
    "                ## Tracker - Left Dorsal Organ\n",
    "                if ldo[2] > min_conf_ldo:\n",
    "                    cv2.rectangle(frame_overlay, (ldo[0] - ldo[3], ldo[1] - ldo[3]),\n",
    "                                  (ldo[0] + ldo[3], ldo[1] + ldo[3]),\n",
    "                                  color=(125, 125, 255), thickness=-1)\n",
    "\n",
    "                ## Tracker - Right Dorsal Organ\n",
    "                if rdo[2] > min_conf_rdo:\n",
    "                    cv2.rectangle(frame_overlay, (rdo[0] - rdo[3], rdo[1] - rdo[3]),\n",
    "                                  (rdo[0] + rdo[3], rdo[1] + rdo[3]),\n",
    "                                  color=(0, 255, 0), thickness=-1)\n",
    "\n",
    "                ## Tracker - Left MouthHook\n",
    "                if lmh[2] > min_conf_lmh:\n",
    "                    cv2.rectangle(frame_overlay, (lmh[0] - lmh[3], lmh[1] - lmh[3]),\n",
    "                                  (lmh[0] + lmh[3], lmh[1] + lmh[3]),\n",
    "                                  color=(100, 160, 220), thickness=-1)\n",
    "\n",
    "                ## Tracker - Right MouthHook\n",
    "                if rmh[2] > min_conf_rmh:\n",
    "                    cv2.rectangle(frame_overlay, (rmh[0] - rmh[3], rmh[1] - rmh[3]),\n",
    "                                  (rmh[0] + rmh[3], rmh[1] + rmh[3]),\n",
    "                                  color=(100, 200, 200), thickness=-1)\n",
    "                \n",
    "            ## The Cropped frame sent to FPGA\n",
    "            cv2.rectangle(frame_overlay, (cropCenter_X - 128, cropCenter_Y - 128),\n",
    "                          (cropCenter_X + 128, cropCenter_Y + 128), color=(200, 200, 200), thickness=1)\n",
    "\n",
    "#################################################################################################################\n",
    "############################ Mark the annotated positions using a circle ########################################\n",
    "#################################################################################################################\n",
    "\n",
    "            ## Annotation - MouthHook\n",
    "            cv2.circle(frame_overlay, (int(row['MouthHook_x_A']), int(row['MouthHook_y_A'])),\n",
    "                       radius=5, color=(255, 0, 0), thickness=-1)\n",
    "\n",
    "            ## Annotation - Left Dorsal Organ                \n",
    "            cv2.circle(frame_overlay, (int(row['LeftDorsalOrgan_x_A']), int(row['LeftDorsalOrgan_y_A'])),\n",
    "                       radius=5, color=(125, 125, 255), thickness=-1)\n",
    "\n",
    "            ## Annotation - Right Dorsal Organ\n",
    "            cv2.circle(frame_overlay, (int(row['RightDorsalOrgan_x_A']), int(row['RightDorsalOrgan_y_A'])),\n",
    "                       radius=5, color=(0, 255, 0), thickness=-1)   \n",
    "\n",
    "            ## Annotation - Left MouthHook                \n",
    "            cv2.circle(frame_overlay, (int(row['LeftMHhook_x_A']), int(row['LeftMHhook_y_A'])),\n",
    "                       radius=3, color=(100, 160, 220), thickness=-1)\n",
    "\n",
    "            ## Annotation - Right MouthHook\n",
    "            cv2.circle(frame_overlay, (int(row['RightMHhook_x_A']), int(row['RightMHhook_y_A'])),\n",
    "                       radius=3, color=(100, 200, 200), thickness=-1)   \n",
    "\n",
    "            ## Crop the frame\n",
    "            crop_x = int(max(0, cropCenter_X-int(crop_size/2)))\n",
    "            crop_y = int(max(0, cropCenter_Y-int(crop_size/2)))\n",
    "\n",
    "            frame_crop = frame[crop_y:crop_y+crop_size, crop_x:crop_x+crop_size]\n",
    "            frame_crop_overlay = frame_overlay[crop_y:crop_y+crop_size, crop_x:crop_x+crop_size]\n",
    "            \n",
    "            frame_gray_scale = cv2.cvtColor(frame[0:100, 0:100], cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "            ## Display statistics at the top-right corner\n",
    "            cv2.putText(frame_crop, '%03d'%(this_frame), (350, 40), font, 0.65, (0, 0, 0), 2, cv2.LINE_AA)\n",
    "            cv2.putText(frame_crop, 'Conf', (405, 40), font, 0.5, (0, 0, 0), 2, cv2.LINE_AA)\n",
    "            cv2.putText(frame_crop, 'Err', (455, 40), font, 0.5, (0, 0, 0), 2, cv2.LINE_AA)\n",
    "\n",
    "            cv2.putText(frame_crop, '%s: %0.2f %2.1f' % (' MH', mh[2], row['MouthHook_dist']), (350, 60), font, 0.65, (255, 0, 0), 2, cv2.LINE_AA)\n",
    "            cv2.putText(frame_crop, '%s: %0.2f %2.1f' % ('LDO', ldo[2], row['LeftDorsalOrgan_dist']), (350, 80), font, 0.65, (125, 125, 255), 2, cv2.LINE_AA)\n",
    "            cv2.putText(frame_crop, '%s: %0.2f %2.1f' % ('RDO', rdo[2], row['RightDorsalOrgan_dist']), (350, 100), font, 0.65, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "            cv2.putText(frame_crop, '%s: %0.2f %2.1f' % ('LMH', lmh[2], row['LeftMHhook_dist']), (350, 120), font, 0.65, (100, 160, 220), 2, cv2.LINE_AA)\n",
    "            cv2.putText(frame_crop, '%s: %0.2f %2.1f' % ('RMH', rmh[2], row['RightMHhook_dist']), (350, 140), font, 0.65, (100, 200, 200), 2, cv2.LINE_AA)\n",
    "            cv2.putText(frame_crop, '  KP: %02d' % (nkp), (350, 160), font, 0.65, (0, 0, 0), 2, cv2.LINE_AA)\n",
    "            cv2.putText(frame_crop, 'Spot: %02d um' % (spot_size*2.75), (350, 180), font, 0.65, (0, 0, 0), 2, cv2.LINE_AA)\n",
    "            cv2.putText(frame_crop, 'Gray: %03d' % (np.mean(frame_gray_scale)), (350, 200), font, 0.65, (0, 0, 0), 2, cv2.LINE_AA)            \n",
    "\n",
    "            ## To make the rectangle and circle slightly transparent\n",
    "            alpha = 0.3\n",
    "            cv2.addWeighted(frame_crop_overlay, alpha, frame_crop, 1 - alpha, 0, frame_crop)\n",
    "            cv2.addWeighted(frame_overlay, alpha, frame, 1 - alpha, 0, frame)\n",
    "            video_crop.write(frame_crop)\n",
    "\n",
    "            ## Uncomment when saving the complete frame\n",
    "#             video.write(frame)          \n",
    "\n",
    "    cv2.destroyAllWindows()\n",
    "    video_crop.release()\n",
    "\n",
    "    ## Uncomment when saving the complete frame    \n",
    "#     video.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  },
  "notify_time": "5",
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
